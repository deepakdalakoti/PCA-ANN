{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'cantera._cantera' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA \n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, GaussianNoise\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D \n",
    "import keras.backend as K\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, FeatureAgglomeration\n",
    "from sklearn.metrics import r2_score\n",
    "from multiprocessing import Pool\n",
    "import pickle \n",
    "import cantera as ct\n",
    "from cantera import ck2cti\n",
    "from scipy.interpolate import griddata, RegularGridInterpolator, LinearNDInterpolator\n",
    "import h5py\n",
    "from scipy.stats import binned_statistic, skew, binned_statistic_2d,binned_statistic_dd\n",
    "import os\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from scipy.signal import savgol_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composition={'AC3H5':[3,5,0,0],'C10H20':[10,20,0,0],'C12H24':[12,24,0,0],'C12H25O2':[12,25,2,0],'C12OOH':[12,25,2,0],'C2H2':[2,2,0,0],\n",
    " 'C2H3':[2,3,0,0],'C2H3CHO':[3,4,1,0],'C2H4':[2,4,0,0],'C2H5':[2,5,0,0],'C2H6':[2,6,0,0],'C3H6':[3,6,0,0],'C4H7':[4,7,0,0],\n",
    "'C4H81':[4,8,0,0],'C5H10':[5,10,0,0],'C5H9':[5,9,0,0],'C6H12':[6,12,0,0],'C7H14':[7,14,0,0],'C8H16':[8,16,0,0],'C9H18':[9,18,0,0],\n",
    " 'CH2':[1,2,0,0],'CH2*':[1,2,0,0],'CH2CHO':[2,3,1,0],'CH2O':[1,2,1,0],'CH3':[1,3,0,0],'CH3O':[1,3,1,0],'CH4':[1,4,0,0],\n",
    " 'CO':[1,0,1,0],'CO2':[1,0,2,0],'H':[0,1,0,0],'H2':[0,2,0,0],'H2O':[0,2,1,0],'H2O2':[0,2,2,0],'HCO':[1,1,1,0],\n",
    " 'HO2':[0,1,2,0],'N2':[0,0,0,2],'NC12H26':[12,26,0,0],'C3H7':[3,7,0,0],'O':[0,0,1,0],'O2':[0,0,2,0],'O2C12H24OOH':[12,25,4,0],\n",
    " 'OC12H23OOH':[12,24,3,0],'OH':[0,1,1,0],'C4H9':[4,9,0,0],'PXC10H21':[10,21,0,0],'PXC12H25':[12,25,0,0],'PXC5H11':[5,11,0,0],\n",
    " 'C6H13':[6,13,0,0],'PXC7H15':[7,15,0,0],'C8H17':[8,17,0,0],'PXC9H19':[9,19,0,0],'S3XC12H25':[12,25,0,0],'SXC12H25':[12,25,0,0]}\n",
    "\n",
    "specs=['AC3H5','C10H20','C12H24','C12H25O2','C12OOH','C2H2','C2H3','C2H3CHO','C2H4','C2H5','C2H6','C3H6','C4H7',\n",
    "'C4H81','C5H10','C5H9','C6H12','C7H14','C8H16','C9H18','CH2','CH2*','CH2CHO','CH2O','CH3','CH3O','CH4',\n",
    " 'CO','CO2','H','H2','H2O','H2O2','HCO','HO2','N2','NC12H26','C3H7','O','O2','O2C12H24OOH','OC12H23OOH','OH','C4H9','PXC10H21','PXC12H25','PXC5H11',\n",
    " 'C6H13','PXC7H15','C8H17','PXC9H19','S3XC12H25','SXC12H25']\n",
    "molar_mass = np.zeros(53)\n",
    "aij = np.zeros((53,4))\n",
    "j=0\n",
    "for spec in specs:\n",
    "    atoms = composition[spec]\n",
    "    aij[j,:]=atoms\n",
    "    molar_mass[j] = atoms[0]*12+atoms[1]+atoms[2]*16+atoms[3]*14\n",
    "    j=j+1\n",
    "atom_mass = np.zeros(4)    \n",
    "atom_mass[0]=12\n",
    "atom_mass[1]=1\n",
    "atom_mass[2]=16\n",
    "atom_mass[3]=14\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " specs=['aC3H5','C10H20','C12H24','C12H25O2','C12OOH','C2H2','C2H3','C2H3CHO','C2H4','C2H5','C2H6','C3H6','C4H7',\n",
    "'C4H81','C5H10','C5H9','C6H12','C7H14','C8H16','C9H18','CH2','CH2*','CH2CHO','CH2O','CH3','CH3O','CH4',\n",
    " 'CO','CO2','H','H2','H2O','H2O2','HCO','HO2','N2','NC12H26','nC3H7','O','O2','O2C12H24OOH','OC12H23OOH','OH','pC4H9','PXC10H21','PXC12H25','PXC5H11',\n",
    " 'PXC6H13','PXC7H15','PXC8H17','PXC9H19','S3XC12H25','SXC12H25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_NP=['N2','H','O2','OH','O','H2','H2O','HO2','H2O2','CO2','CO','HCO','CH2O','CH2','CH3','C2H2','CH2*','CH3O','CH4','C2H4',\n",
    "          'C2H6','C2H5','C2H3','aC3H5','CH2CHO','C2H3CHO','C3H6','nC3H7','C4H7','C4H81','pC4H9','C5H9','C5H10','PXC5H11','C6H12','PXC6H13',\n",
    "          'C7H14','PXC7H15','C8H16','PXC8H17','C9H18','PXC9H19','C10H20','PXC10H21','C12H24','PXC12H25','S3XC12H25','SXC12H25',\n",
    "          'NC12H26','C12H25O2','C12OOH','O2C12H24OOH','OC12H23OOH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_molar_mass(molar_mass,data):\n",
    "    mean_mass = np.zeros((data.shape[0]))\n",
    "    mean_mass = 1.0/np.sum(data[:,0:molar_mass.shape[0]]/molar_mass[None,:],1)\n",
    "    \n",
    "    return mean_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_spec=[]\n",
    "for i in range(0,53):\n",
    "   for j in range(0,53):\n",
    "       if(specs[i]==specs_NP[j]):\n",
    "           print(specs[i],specs_NP[j],j,i)\n",
    "           map_spec.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_2d(file):\n",
    "    f = h5py.File(file,'r')\n",
    "    dset = f['DATA'][:,:,3:54+3]\n",
    "    T  = f['DATA'][:,:,2]\n",
    "    dset=np.delete(dset,1,axis=2)\n",
    "    dset = np.reshape(dset,(dset.shape[0]*dset.shape[1],53))\n",
    "    T = np.reshape(T,(T.shape[0]*T.shape[1],1))\n",
    "    data = dset[:,map_spec]\n",
    "    data = np.append(data,T,axis=1)\n",
    "    data = data[0:-1:2,:]\n",
    "    return data\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reac_2d(file):\n",
    "    f = h5py.File(file,'r')\n",
    "    dset = f['DATA'][:,:,65:119]\n",
    "    HRR  = -f['DATA'][:,:,60]\n",
    "    dset=np.delete(dset,1,axis=2)\n",
    "    dset = np.reshape(dset,(dset.shape[0]*dset.shape[1],53))\n",
    "    HRR = np.reshape(HRR,(HRR.shape[0]*HRR.shape[1],1))\n",
    "    data = dset[:,map_spec]\n",
    "    data = np.append(data,HRR,axis=1)\n",
    "    data = data[0:-1:2,:]\n",
    "    return data\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mass = get_mean_molar_mass(molar_mass,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atoms_conservation(data):\n",
    "    out = np.zeros((data.shape[0],4))\n",
    "    out = np.matmul((data[:,0:53]/molar_mass),aij*atom_mass)\n",
    "    return out\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas = ct.Solution('nDodecane_sk54.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cp(data):\n",
    "  enth_mass3d_p =[]\n",
    "  for i in range(0,data.shape[0]):\n",
    "    comp = dict(zip(specs,data[i,0:53]))\n",
    "    gas.TPY = data[i,53],6079500,comp\n",
    "    q1 = ct.Quantity(gas)\n",
    "    enth_mass3d_p.append(q1.cp_mass)\n",
    "  return enth_mass3d_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enthalpy(data):\n",
    "  enth_mass3d_p =[]\n",
    "  for i in range(0,data.shape[0]):\n",
    "    comp = dict(zip(specs,data[i,0:53]))\n",
    "    gas.TPY = data[i,53],6079500,comp\n",
    "    q1 = ct.Quantity(gas)\n",
    "    enth_mass3d_p.append(q1.enthalpy_mass)\n",
    "  return enth_mass3d_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viscosity(data):\n",
    "  enth_mass3d_p =[]\n",
    "  for i in range(0,data.shape[0]):\n",
    "    comp = dict(zip(specs,data[i,0:53]))\n",
    "    gas.TPY = data[i,53],6079500,comp\n",
    "    q1 = ct.Quantity(gas)\n",
    "    enth_mass3d_p.append(q1.viscosity)\n",
    "  return enth_mass3d_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conductivity(data):\n",
    "  enth_mass3d_p =[]\n",
    "  for i in range(0,data.shape[0]):\n",
    "    comp = dict(zip(specs,data[i,0:53]))\n",
    "    gas.TPY = data[i,53],6079500,comp\n",
    "    q1 = ct.Quantity(gas)\n",
    "    enth_mass3d_p.append(q1.thermal_conductivity)\n",
    "  return enth_mass3d_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reaction(data):\n",
    "  rr = np.zeros((data.shape[0],54))\n",
    "  for i in range(0,data.shape[0]):\n",
    "    comp = dict(zip(specs,data[i,0:53]))\n",
    "    gas.TPY = data[i,53],6079500,comp\n",
    "    q1 = ct.Quantity(gas)\n",
    "    rr[i,:]=q1.net_production_rates\n",
    "  specs_cantera=gas.species_names\n",
    "  specs_cantera.remove('AR')\n",
    "  rr = np.delete(rr,1,1)\n",
    "  map_spec=[]\n",
    "  for i in range(0,53):\n",
    "     for j in range(0,53):\n",
    "         if(specs[i]==specs_cantera[j]):\n",
    "             map_spec.append(j)\n",
    "  rr = rr[:,map_spec]\n",
    "  return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diffusion(data):\n",
    "  rr = np.zeros((data.shape[0],54))\n",
    "  for i in range(0,data.shape[0]):\n",
    "    comp = dict(zip(specs,data[i,0:53]))\n",
    "    gas.TPY = data[i,53],6079500,comp\n",
    "    q1 = ct.Quantity(gas)\n",
    "    rr[i,:]=q1.mix_diff_coeffs_mass\n",
    "  specs_cantera=gas.species_names\n",
    "  specs_cantera.remove('AR')\n",
    "  rr = np.delete(rr,1,1)\n",
    "  map_spec=[]\n",
    "  for i in range(0,53):\n",
    "     for j in range(0,53):\n",
    "         if(specs[i]==specs_cantera[j]):\n",
    "             map_spec.append(j)\n",
    "  rr = rr[:,map_spec]\n",
    "\n",
    "  return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_cantera=gas.species_names\n",
    "specs_cantera.remove('AR')  \n",
    "map_spec=[]\n",
    "for i in range(0,53):\n",
    "   for j in range(0,53):\n",
    "       if(specs[i]==specs_cantera[j]):\n",
    "           print(specs[i],specs_cantera[j],j)\n",
    "           map_spec.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_est(Xt,data,nbins):\n",
    "    \n",
    "       \n",
    "    cond_mean, _ , bins = binned_statistic_dd(Xt,data,bins=nbins,expand_binnumbers=True)\n",
    "    cond_mean[np.isnan(cond_mean)]=0\n",
    "    bins = bins-1\n",
    "    bins[bins==nbins]=nbins-1\n",
    "    pred = np.zeros(Xt.shape[0])\n",
    "    #for i in range(0,Xt.shape[0]):\n",
    "    pred=cond_mean[bins[0,:],bins[1,:],bins[2,:],bins[3,:],bins[4,:]]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_noholes(Xt,data,Xt3d,nbins):\n",
    "           \n",
    "    grid = np.linspace(np.min(Xt,0),np.max(Xt,0),nbins)\n",
    "    xi,yi = np.meshgrid(grid[:,0],grid[:,1])\n",
    "    cond_mean = griddata((Xt[:,0],Xt[:,1]),data,(xi,yi),method='linear')\n",
    "    indices = np.argwhere(np.isnan(cond_mean))\n",
    "    cond_mean[indices[:,0],indices[:,1]] = griddata((Xt[:,0],Xt[:,1]),data,(xi[indices[:,0],indices[:,1]],yi[indices[:,0],indices[:,1]]),method='nearest')\n",
    "    \n",
    "    #print(np.sum(np.isnan(cond_mean)))    \n",
    "    \n",
    "    \n",
    "    bins = ((Xt3d-np.min(Xt,0))/(np.max(Xt,0)-np.min(Xt,0)))*nbins \n",
    "    bins = bins.astype(int)\n",
    "    bins[bins>nbins-1]=nbins-1\n",
    "    bins[bins<0]=0    \n",
    "    pred=cond_mean[bins[:,1],bins[:,0]]\n",
    "    \n",
    "    #pred[np.isnan(pred)]=0\n",
    "    \n",
    "    #cond_mean = np.transpose(cond_mean)\n",
    "    \n",
    "    #interp=RegularGridInterpolator((grid[:,0],grid[:,1]),cond_mean,method='linear',bounds_error=False,fill_value=0)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #interp = LinearNDInterpolator(grid,cond_mean,Xt3d)\n",
    "\n",
    "    \n",
    "    \n",
    "    return  pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_noholes3d(Xt,data,Xt3d,nbins):\n",
    "           \n",
    "    grid = np.linspace(np.min(Xt,0),np.max(Xt,0),nbins)\n",
    "    xi,yi,zi = np.meshgrid(grid[:,0],grid[:,1],grid[:,2])\n",
    "    cond_mean = griddata((Xt[:,0],Xt[:,1],Xt[:,2]),data,(xi,yi,zi),method='linear')\n",
    "    indices = np.argwhere(np.isnan(cond_mean))\n",
    "    cond_mean[indices[:,0],indices[:,1],indices[:,2]] = griddata((Xt[:,0],Xt[:,1],Xt[:,2]),data,(xi[indices[:,0],indices[:,1],indices[:,2]],yi[indices[:,0],indices[:,1],indices[:,2]],zi[indices[:,0],indices[:,1],indices[:,2]]),method='nearest')\n",
    "    \n",
    "    print(np.sum(np.isnan(cond_mean)))    \n",
    "    \n",
    "    \n",
    "    bins = ((Xt3d-np.min(Xt,0))/(np.max(Xt,0)-np.min(Xt,0)))*nbins \n",
    "    bins = bins.astype(int)\n",
    "    bins[bins>nbins-1]=nbins-1\n",
    "    bins[bins<0]=0    \n",
    "    pred=cond_mean[bins[:,1],bins[:,0],bins[:,2]]\n",
    "    pred[np.isnan(pred)]=0\n",
    "    \n",
    "    #cond_mean = np.transpose(cond_mean)\n",
    "    \n",
    "    #interp=RegularGridInterpolator((grid[:,0],grid[:,1]),cond_mean,method='linear',bounds_error=False,fill_value=0)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #interp = LinearNDInterpolator(grid,cond_mean,Xt3d)\n",
    "\n",
    "    \n",
    "    \n",
    "    return  pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(Xt,data,Xt3d,nbins):\n",
    "           \n",
    "    cond_mean, _ , _ = binned_statistic_dd(Xt,data,bins=nbins,expand_binnumbers=True)\n",
    "    cond_mean[np.isnan(cond_mean)]=0\n",
    "    bins = np.zeros((Xt3d.shape[0],3))\n",
    "    bins = ((Xt3d-np.min(Xt,0))/(np.max(Xt,0)-np.min(Xt,0)))*nbins \n",
    "    bins = bins.astype(int)\n",
    "    bins[bins>nbins-1]=nbins-1\n",
    "    bins[bins<0]=0    \n",
    "    pred=cond_mean[bins[:,0],bins[:,1]]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_mean(Xt,data,nbins):\n",
    "           \n",
    "    cond_mean, _ , _ = binned_statistic_dd(Xt,data,bins=nbins,expand_binnumbers=True)\n",
    "    cond_mean[np.isnan(cond_mean)]=0\n",
    "    cond_mean = np.transpose(cond_mean)\n",
    "    \n",
    "    #grid = np.linspace(np.min(Xt,0),np.max(Xt,0),nbins)\n",
    "    #xi,yi = np.meshgrid(grid[:,0],grid[:,1])\n",
    "    #cond_mean = griddata((Xt[:,0],Xt[:,1]),data,(xi,yi),method='linear')\n",
    "    #indices = np.argwhere(np.isnan(cond_mean))\n",
    "    #cond_mean[indices[:,0],indices[:,1]] = griddata((Xt[:,0],Xt[:,1]),data,(xi[indices[:,0],indices[:,1]],yi[indices[:,0],indices[:,1]]),method='nearest')\n",
    "    #cond_mean = np.transpose(cond_mean)\n",
    "    \n",
    "    return cond_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bin_test = np.arange(10,200,10)\n",
    "res_Yc = np.zeros(bin_test.shape[0])\n",
    "res_Xt = np.zeros(bin_test.shape[0])\n",
    "for i,bins in enumerate(bin_test):\n",
    "    pred = get_table_noholes(Yc2d[:,0:2],reac[:,53],Yc3d[:,0:2],bins)\n",
    "    res_Yc[i] = np.sqrt(mean_squared_error(reac3d[:,53],pred)/np.mean(reac3d[:,53]**2))    \n",
    "    pred = get_table_noholes(Xt[:,0:2],reac[:,53],Xt3d[:,0:2],bins)\n",
    "    res_Xt[i] = np.sqrt(mean_squared_error(reac3d[:,53],pred)/np.mean(reac3d[:,53]**2))    \n",
    "    print(i,bins)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_est3(Xt,data,nbins):\n",
    "    \n",
    "    out = np.zeros((nbins,nbins,nbins))\n",
    "    count = np.ones((nbins,nbins,nbins))\n",
    "    mins = np.min(Xt,0)\n",
    "    maxs = np.max(Xt,0)\n",
    "    pred = np.zeros(data.shape[0])\n",
    "    for i in range(0,Xt.shape[0]):\n",
    "        x1 = np.zeros(3)\n",
    "        for j in range(0,3):\n",
    "            x1[j] = int((Xt[i,j]-mins[j])/(maxs[j]-mins[j])*nbins)\n",
    "            if(x1[j]>nbins-1):\n",
    "                x1[j]=nbins-1\n",
    "            \n",
    "        x1 = x1.astype(int)    \n",
    "        \n",
    "        out[x1[0],x1[1],x1[2]]  = out[x1[0],x1[1],x1[2]] +data[i]\n",
    "        count[x1[0],x1[1],x1[2]]  = count[x1[0],x1[1],x1[2]] +1\n",
    "        \n",
    "    out  = out/count\n",
    "    out[np.isnan(out)]=0\n",
    "\n",
    "    for i in range(0,Xt.shape[0]):\n",
    "        x1 = np.zeros(3)\n",
    "        for j in range(0,3):\n",
    "            x1[j] = int((Xt[i,j]-mins[j])/(maxs[j]-mins[j])*nbins)\n",
    "            if(x1[j]>nbins-1):\n",
    "                x1[j]=nbins-1\n",
    "        x1 = x1.astype(int)    \n",
    "        pred[i]=out[x1[0],x1[1],x1[2]]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_est2(Xt,data,nbins):\n",
    "    \n",
    "    out = np.zeros((nbins,nbins))\n",
    "    count = np.zeros((nbins,nbins))\n",
    "    mins = np.min(Xt,0)\n",
    "    maxs = np.max(Xt,0)\n",
    "    pred = np.zeros(data.shape[0])\n",
    "    for i in range(0,Xt.shape[0]):\n",
    "        x1 = np.zeros(2)\n",
    "        for j in range(0,2):\n",
    "            x1[j] = int((Xt[i,j]-mins[j])/(maxs[j]-mins[j])*nbins)\n",
    "            if(x1[j]>nbins-1):\n",
    "                x1[j]=nbins-1\n",
    "            \n",
    "        x1 = x1.astype(int)    \n",
    "        \n",
    "        out[x1[0],x1[1]]  = out[x1[0],x1[1]] +data[i]\n",
    "        count[x1[0],x1[1]]  = count[x1[0],x1[1]] +1\n",
    "        \n",
    "    out  = out/count\n",
    "    out[np.isnan(out)]=0\n",
    "    for i in range(0,Xt.shape[0]):\n",
    "        x1 = np.zeros(2)\n",
    "        for j in range(0,2):\n",
    "            x1[j] = int((Xt[i,j]-mins[j])/(maxs[j]-mins[j])*nbins)\n",
    "            if(x1[j]>nbins-1):\n",
    "                x1[j]=nbins-1\n",
    "        x1 = x1.astype(int)    \n",
    "        pred[i]=out[x1[0],x1[1]]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fname,nc):    \n",
    "    data = np.fromfile(fname,dtype=np.single)\n",
    "    data = np.reshape(data,(int(data.size/nc),nc))\n",
    "    #HRR = data[:,0]\n",
    "    data = np.delete(data,0,1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_mem(fname,nc):    \n",
    "    data = np.memmap(fname, dtype=np.single, mode='r')    \n",
    "    data = np.reshape(data,(int(data.size/nc),nc))\n",
    "    #HRR = data[:,0]\n",
    "    data = np.delete(data,0,1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reaction(fname):    \n",
    "    data = np.fromfile(fname,dtype=np.single)\n",
    "    data = np.reshape(data,(int(data.size/56),56))\n",
    "    HRR = data[:,0]\n",
    "    data = np.delete(data,0,1)\n",
    "    data[:,53]=HRR\n",
    "    data = np.delete(data,54,1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reaction_mem(fname):    \n",
    "    data = np.memmap(fname, dtype=np.single, mode='r')    \n",
    "    data = np.reshape(data,(int(data.size/56),56))\n",
    "    HRR = data[:,0]\n",
    "    data = np.delete(data,0,1)\n",
    "    data[:,53]=HRR\n",
    "    data = np.delete(data,54,1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_normalization(data,data2,which):\n",
    "    if(which=='range'):\n",
    "        datanorm = (data-np.mean(data2,0))/(np.max(data2,0)-np.min(data2,0))\n",
    "        return datanorm\n",
    "    elif(which=='std'):\n",
    "        datanorm = (data-np.mean(data2,0))/(np.std(data2,0))\n",
    "        return datanorm\n",
    "    elif(which=='level'):\n",
    "        datanorm = (data-np.mean(data2,0))/(np.mean(data2,0))\n",
    "        return datanorm\n",
    "    elif(which=='vast'):\n",
    "        datanorm = (data-np.mean(data2,0))/(np.std(data2,0))*np.mean(data2,0)\n",
    "        return datanorm\n",
    "    elif(which=='pareto'):\n",
    "        datanorm = (data-np.mean(data2,0))/np.sqrt(np.std(data2,0))\n",
    "        return datanorm\n",
    "    elif(which=='minmax'):\n",
    "        datanorm = (data-np.min(data2,0))/(np.max(data2,0)-np.min(data2,0))\n",
    "        return datanorm\n",
    "    elif(which=='none'):\n",
    "\n",
    "        return np.copy(data)\n",
    "    \n",
    "def do_inverse_norm(data,datanorm,which):\n",
    "    if(which=='range'):\n",
    "        data_inv = datanorm*(np.max(data,0)-np.min(data,0))+np.mean(data,0)\n",
    "        return data_inv\n",
    "    if(which=='std'):\n",
    "        data_inv = datanorm*(np.std(data,0))+np.mean(data,0)\n",
    "        return data_inv\n",
    "    if(which=='level'):\n",
    "        data_inv = datanorm*(np.mean(data,0))+np.mean(data,0)\n",
    "        return data_inv\n",
    "    if(which=='vast'):\n",
    "        data_inv = datanorm*(np.std(data,0))/np.mean(data,0)+np.mean(data,0)\n",
    "        return data_inv\n",
    "    if(which=='pareto'):\n",
    "        data_inv = datanorm*np.sqrt(np.std(data,0))+np.mean(data,0)\n",
    "        return data_inv\n",
    "    if(which=='minmax'):\n",
    "        data_inv = datanorm*(np.max(data,0)-np.min(data,0))+np.min(data,0)\n",
    "        return data_inv\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table(Xt,Xt3d,data):\n",
    "    ng = 10\n",
    "    gridx = np.zeros((ng,Xt.shape[1]))\n",
    "    for i in range(0,Xt.shape[1]):\n",
    "        gridx[:,i] = np.linspace(np.min(Xt[:,i]),np.max(Xt[:,i]),ng)\n",
    "    return   np.meshgrid(gridx[:,0],gridx[:,1],gridx[:,2],gridx[:,3],gridx[:,4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0D = np.fromfile('../PCA/data_0D.bin',dtype=np.single)\n",
    "data0D = np.reshape(data0D,(56,int(data0D.size/56)))   \n",
    "data0D = data0D.T\n",
    "data0D = np.delete(data0D,0,1)\n",
    "\n",
    "reac0D = np.fromfile('../PCA/reac_0D.bin',dtype=np.single)\n",
    "reac0D = np.reshape(reac0D,(56,int(reac0D.size/56)))   \n",
    "reac0D = reac0D.T\n",
    "HRR = reac0D[:,0]\n",
    "reac0D = np.delete(reac0D,0,1)\n",
    "reac0D[:,53]=HRR\n",
    "reac0D = np.delete(reac0D,54,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = read_data('../PCA/data2d_lower2_chi.bin',57)\n",
    "data = read_data('../PCA/data2d_lower2.bin',56)\n",
    "#data2 = read_data('../PCA/data2d_lower.bin')\n",
    "data3 = read_data('../PCA/data2d_base.bin',56)\n",
    "\n",
    "#data4 = read_data('../PCA/data2d_high.bin')\n",
    "#dat3d = read_data('../PCA/forPCA_coarse.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = get_data_2d('../PCA/data_10.h5')\n",
    "#data2 = get_data_2d('../PCA/data_5.h5')\n",
    "#data3 = get_data_2d('../PCA/data_15.h5')\n",
    "data = get_data_2d('../PCA/data_20.h5')\n",
    "#data5 = get_data_2d('../PCA/data_25.h5')\n",
    "#data6 = get_data_2d('../PCA/data_30.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reac = get_reac_2d('../PCA/data_10.h5')\n",
    "#reac2 = get_reac_2d('../PCA/data_5.h5')\n",
    "#reac3 = get_reac_2d('../PCA/data_15.h5')\n",
    "reac = get_reac_2d('../PCA/data_20.h5')\n",
    "#reac5 = get_reac_2d('../PCA/data_25.h5')\n",
    "#reac6 = get_reac_2d('../PCA/data_30.h5')\n",
    "\n",
    "\n",
    "#reac2 = get_reac_2d('../PCA/data_10.h5')\n",
    "#reac3 = get_reac_2d('../PCA/data_15.h5')\n",
    "#reac4 = get_reac_2d('../PCA/data_20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "reac = read_reaction('../PCA/reac2d_lower2.bin')\n",
    "#reac2 = read_reaction('../PCA/reac2d_lower.bin')\n",
    "reac3 = read_reaction('../PCA/reac2d_base.bin')\n",
    "#reac4 = read_reaction('../PCA/reac2d_high.bin')\n",
    "#reac3, HRR32d = read_data('../PCA/reac2d_high.bin')\n",
    "#reac2 = read_data('../PCA/reac2d_base.bin')\n",
    "#reac3 = read_data('../PCA/reac2d_high.bin')\n",
    "#reac3d = read_data('../PCA/reac3d.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_CMA(data):\n",
    "    cmas = np.ones(data.shape[0])*5\n",
    "    idxs = np.logical_or(data[:,53] < 1120, data[:,3] > 0.05*max(data[:,3]))\n",
    "    cmas[idxs]=0\n",
    "    idxs = np.logical_and(np.logical_and(np.logical_and(data[:,53] >=1120, data[:,3] < 0.05*max(data[:,3])),data[:,42] < 0.05*max(data[:,42]))\n",
    "            ,data[:,54]>0.046)\n",
    "    cmas[idxs]=1\n",
    "    idxs = np.logical_and(np.logical_and(np.logical_and(data[:,53] >=1120, data[:,3] < 0.05*max(data[:,3])),data[:,42] < 0.05*max(data[:,42]))\n",
    "            ,data[:,54]<0.046)\n",
    "    cmas[idxs]=2\n",
    "    idxs = np.logical_and(np.logical_and(data[:,53] >=1120, data[:,3] < 0.05*max(data[:,3])),data[:,42] > 0.05*max(data[:,42]))\n",
    "            \n",
    "    cmas[idxs]=3\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    return cmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yc2d = np.zeros((data.shape[0],2))\n",
    "Yc2d[:,1] = data[:,27]+data[:,28]+data[:,30]+data[:,31]\n",
    "Yc2d[:,0] =data[:,54]\n",
    "ReacC = reac[:,27]+reac[:,28]+reac[:,30]+reac[:,31]\n",
    "\n",
    "Yc3d = np.zeros((dat3d.shape[0],2))\n",
    "Yc3d[:,1] = dat3d[:,27]+dat3d[:,28]+dat3d[:,30]+dat3d[:,31]\n",
    "Yc3d[:,0] = dat3d[:,54]\n",
    "ReacC3d = reac3d[:,27]+reac3d[:,28]+reac3d[:,30]+reac3d[:,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3d = read_data('../PCA/dat3d.bin',56)\n",
    "reac3d = read_reaction('../PCA/reac3d.bin')\n",
    "\n",
    "#reac3d = read_reaction_mem('../PCA/reac3d_big.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HRR2d = np.copy(reac[:,53])\n",
    "HRR3d = np.copy(reac3d[:,53])\n",
    "HRR3d = do_normalization(HRR3d,HRR2d,'minmax')\n",
    "HRR2d = do_normalization(HRR2d,HRR2d,'minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data,data3))\n",
    "reac = np.concatenate((reac,reac3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = abs(data)\n",
    "dat3d = abs(dat3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc=54\n",
    "datanorm = do_normalization(data[:,0:nc],data[:,0:nc],'range')\n",
    "dat3dnorm = do_normalization(dat3d[:,0:nc],data[:,0:nc],'range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO PCA Here\n",
    "nc=54\n",
    "pca = PCA(n_components=5)\n",
    "Xt= pca.fit_transform(datanorm[:,0:nc])\n",
    "components = pca.components_\n",
    "Xt3d = np.matmul((dat3dnorm[:,0:nc]-np.mean(datanorm[:,0:nc],0)),components.T)\n",
    "#XPCA = pca.inverse_transform(Xt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPCA2D = np.matmul(reac[:,0:nc]/(np.std(data[:,0:nc],0)),components.T)\n",
    "RPCA3D = np.matmul(reac3d[:,0:nc]/(np.std(data[:,0:nc],0)),components.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPCA2D = np.matmul(reac[:,0:nc]/(np.max(data[:,0 :nc],0)-np.min(data[:,0:nc],0)),components.T)\n",
    "RPCA3D = np.matmul(reac3d[:,0:nc]/(np.max(data[:,0:nc],0)-np.min(data[:,0:nc],0)),components.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPCA2D = np.matmul(reac[:,0:nc],components.T)\n",
    "RPCA3D = np.matmul(reac3d[:,0:nc],components.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(RPCA3D[:,1],RPCA3D[:,1],marker='.')\n",
    "plt.scatter(RPCA2D[:,1],RPCA2D[:,1],marker='.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPCA2DN = (RPCA2D[:,0:5]-np.min(RPCA2D[:,0:5],0))/(np.max(RPCA2D[:,0:5],0)-np.min(RPCA2D[:,0:5],0))\n",
    "RPCA3DN = (RPCA3D[:,0:5]-np.min(RPCA2D[:,0:5],0))/(np.max(RPCA2D[:,0:5],0)-np.min(RPCA2D[:,0:5],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    #return K.mean((y_true-y_pred)**2) + (1-K.sum(y_pred)/500)*0.1\n",
    "    alpha=0.2\n",
    "    return  abs(1-K.sum(y_pred*(maxs-mins)+means)/500)*alpha + K.mean((y_true-y_pred)**2)*(1.0-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "def get_model(dimi):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(80,activation='relu',input_dim=dimi ))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(80,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(80,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(nc,activation='linear'))\n",
    "    model.compile(optimizer='nadam',loss='mean_squared_error')\n",
    "    #model.compile(optimizer='nadam',loss=custom_loss)\n",
    "    return model\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanormF = do_normalization(data[:,0:54],data[:,0:54],'std')\n",
    "dat3dnormF = do_normalization(dat3d[:,0:54],data[:,0:54],'std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtN = do_normalization(Xt[:,0:5],Xt[:,0:5],'range')\n",
    "Xt3dN= do_normalization(Xt3d[:,0:5],Xt[:,0:5],'range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nc=53\n",
    "#model = get_model(5)\n",
    "h=model.fit(XtN[:,0:5],datanormF[:,0:53],epochs=20,validation_data=(Xt3dN[:,0:5],dat3dnormF[:,0:53]),batch_size=500)\n",
    "#h=model.fit(Xt[0:-1:1000,0:2],datanorm[0:-1:1000,0:53],epochs=20,batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_atoms_conservation(out3d)\n",
    "atoms_dns = get_atoms_conservation(dat3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('RR-PCA-1.h5')\n",
    "RRpred[:,0]=model.predict(Xt3d)[:,0]\n",
    "model = load_model('RR-PCA-2.h5')\n",
    "RRpred[:,1]=model.predict(Xt3d)[:,0]\n",
    "model = load_model('RR-PCA-3.h5')\n",
    "RRpred[:,2]=model.predict(Xt3d)[:,0]\n",
    "model = load_model('RR-PCA-4.h5')\n",
    "RRpred[:,3]=model.predict(Xt3d)[:,0]\n",
    "model = load_model('RR-PCA-5.h5')\n",
    "RRpred[:,4]=model.predict(Xt3d)[:,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RRpred[:,4] = opt_est(Xt3d,RPCA3D[:,4],75)\n",
    "#RRpred[:,1] = opt_est(Xt3d,RPCA3D[:,1],60)\n",
    "#RRpred[:,2] = opt_est(Xt3d,RPCA3D[:,2],60)\n",
    "#RRpred[:,3] = opt_est(Xt3d,RPCA3D[:,3],60)\n",
    "#RRpred[:,4] = opt_est(Xt3d,RPCA3D[:,4],60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RRpred = opt_est(Xt3d,reac3d[:,53],60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.zeros(RPCA3D.shape[0])\n",
    "error = (RPCA3D[:,0]-RRpred[:,0])**2 + (RPCA3D[:,1]-RRpred[:,1])**2 + (RPCA3D[:,2]-RRpred[:,2])**2 + \\\n",
    "        (RPCA3D[:,3]-RRpred[:,3])**2 + (RPCA3D[:,4]-RRpred[:,4])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.sum((RPCA3D-RRpred)**2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_prop(dimi):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10,input_dim=dimi, activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(10, activation='relu',kernel_initializer='normal'))\n",
    "    \n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    model.compile(optimizer='nadam',loss='mean_squared_error')\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_prop(5)\n",
    "model.fit(Xt[:,0:5],HRR2d,validation_data=(Xt3d[:,0:5],HRR3d),epochs=10,batch_size=500)\n",
    "#model.fit(Yc2d[:,0:2],HRR2d,epochs=20,batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.scatter(dat3d[:,42]/np.max(dat3d[:,42]), pred[:,42]/np.max(dat3d[:,42]),marker='.',c='k',s=10)\n",
    "plt.locator_params(axis='y', nbins=3)\n",
    "plt.locator_params(axis='x', nbins=3)\n",
    "x = np.linspace(0.0,1.0,10)\n",
    "plt.plot(x,x,'r--')\n",
    "plt.xlabel('$DNS$')\n",
    "plt.ylabel('$ANN$')\n",
    "plt.title('$Y(OH)$')\n",
    "plt.xlim((0.0,1.0))\n",
    "plt.ylim((0.0,1.0))\n",
    "plt.grid(alpha=0.2)\n",
    "ax=plt.gca()\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(25)\n",
    "\n",
    "plt.savefig('Final/OH2.png',dpi=300,bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_diff(dimi):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10,input_dim=dimi, activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(10, activation='relu',kernel_initializer='normal'))\n",
    "\n",
    "    model.add(Dense(5,activation='sigmoid'))\n",
    "    model.compile(optimizer='nadam',loss='mean_squared_error')\n",
    "    return model\n",
    "    #model.add(relu(threshold=0.0))\n",
    "    #model.add(Dense(1,activation='relu'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(epochs,nComp,nClust,labels2d,labels3d):\n",
    "    mean_accuracy = np.zeros(6)\n",
    "    mean_accuracy2d = np.zeros(6)\n",
    "    out2d = np.empty([data.shape[0],nc])\n",
    "    out3d = np.empty([dat3d.shape[0],nc])    \n",
    "    \n",
    "       \n",
    "    for i in range(0,nClust):\n",
    "        print(\"Processing cluster %d\",i)    \n",
    "        model = get_model(nComp)\n",
    "        bsize = int(datanorm[labels2d==i,0].shape[0]/300)\n",
    "        if(bsize>800):\n",
    "            bsize=800\n",
    "        if(bsize<100):\n",
    "            bsize=100           \n",
    "        \n",
    "        model.fit(Xt[labels2d==i,0:nComp],datanorm[labels2d==i,0:nc],epochs=epochs,batch_size=500)    \n",
    "        pred = model.predict(Xt[labels2d==i,0:nComp])\n",
    "        index2d = np.where(labels2d==i)\n",
    "        out2d[index2d,:] = pred.copy()     \n",
    "        pred = model.predict(Xt3d[labels3d==i,0:nComp])\n",
    "        if pred==[] or (not  pred.any()):\n",
    "                continue\n",
    "        index3d = np.where(labels3d==i)\n",
    "        out3d[index3d,:] = pred.copy()\n",
    "        \n",
    "    out2d = out2d*(np.max(data[:,0:nc],0)-np.min(data[:,0:nc],0))+np.min(data[:,0:nc],0)\n",
    "    out3d = out3d*(np.max(data[:,0:nc],0)-np.min(data[:,0:nc],0))+np.min(data[:,0:nc],0)\n",
    "        \n",
    "    #atoms2D=get_atoms_conservation(data[:,0:53])\n",
    "    #atoms2D_pred=get_atoms_conservation(out2d[:,0:53])\n",
    "    #atoms3D=get_atoms_conservation(dat3d[:,0:53])\n",
    "    #atoms3D_pred=get_atoms_conservation(out3d[:,0:53])\n",
    "        \n",
    "    R2Score2D = np.zeros(nc)\n",
    "    R2Score3D = np.zeros(nc)\n",
    "    eps2D = np.zeros(nc)\n",
    "    eps3D = np.zeros(nc)\n",
    "    for i in range(0,nc):\n",
    "            R2Score2D[i]= r2_score(data[:,i],out2d[:,i])\n",
    "            R2Score3D[i]= r2_score(dat3d[:,i],out3d[:,i])\n",
    "            eps2D[i] = mean_squared_error(data[:,i],out2d[:,i])/np.mean(data[:,i]**2)\n",
    "            eps3D[i] = mean_squared_error(dat3d[:,i],out3d[:,i])/np.mean(dat3d[:,i]**2)\n",
    "            \n",
    "    mean_accuracy2d[0] = np.mean(R2Score2D)\n",
    "    mean_accuracy2d[1] = np.mean(abs(1-np.sum(out2d[:,0:53],1)))\n",
    "    mean_accuracy2d[2] = np.max(abs(1-np.sum(out2d[:,0:53],1)))\n",
    "    \n",
    "    mean_accuracy[0] = np.mean(R2Score3D)\n",
    "    mean_accuracy[1] = np.mean(abs(1-np.sum(out3d[:,0:53],1)))\n",
    "    mean_accuracy[2] = np.max(abs(1-np.sum(out3d[:,0:53],1)))\n",
    "    \n",
    "    #for j in range(0,4):\n",
    "    #    mean_accuracy2d[j+2] = np.mean(abs(1.0-atoms2D_pred[:,j]/atoms2D[:,j]))\n",
    "    #    mean_accuracy[j+2] = np.mean(abs(1.0-atoms3D_pred[:,j]/atoms3D[:,j]))       \n",
    "        \n",
    "    return mean_accuracy2d,mean_accuracy, R2Score2D, R2Score3D,eps2D,eps3D, out2d, out3d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_reac(epochs,nComp,nClust,labels2d,labels3d,rindx):\n",
    "    \n",
    "    out2d = np.zeros((data.shape[0],1))\n",
    "    out3d = np.zeros((dat3d.shape[0],1))\n",
    "    \n",
    "    for i in range(0,nClust):\n",
    "        print(\"Processing cluster %d\",i)    \n",
    "        model = get_model_reac(nComp)\n",
    "        #model.load_weights('model.h5')        \n",
    "        bsize = int((RPCA2D[labels2d==i,rindx].shape[0])/300)\n",
    "        if(bsize>800):\n",
    "            bsize=800\n",
    "        if(bsize<100):\n",
    "            bsize=100           \n",
    "        \n",
    "        h=model.fit(Xt[labels2d==i,0:nComp],RPCA2DN[labels2d==i,rindx],epochs=epochs,batch_size=500)    \n",
    "        pred = model.predict(Xt[labels2d==i,0:nComp])\n",
    "        index2d = np.where(labels2d==i)\n",
    "        out2d[index2d,:] = pred.copy()     \n",
    "        pred = model.predict(Xt3d[labels3d==i,0:nComp])\n",
    "        if pred==[] or (not  pred.any()):\n",
    "                continue\n",
    "        index3d = np.where(labels3d==i)\n",
    "        out3d[index3d,:] = pred.copy()\n",
    "        \n",
    "    out2d = out2d*(np.max(RPCA2D[:,rindx])-np.min(RPCA2D[:,rindx]))+np.min(RPCA2D[:,rindx])\n",
    "    out3d = out3d*(np.max(RPCA2D[:,rindx])-np.min(RPCA2D[:,rindx]))+np.min(RPCA2D[:,rindx])\n",
    "    #out2d = do_inv_norm_neg(RPCA2D[:,rindx],out2d)\n",
    "    #out3d = do_inv_norm_neg(RPCA2D[:,rindx],out3d)\n",
    "    #out2d=out2d*np.std(RPCA2D[:,rindx],0)+np.mean(RPCA2D[:,rindx],0)\n",
    "    #out3d=out3d*np.std(RPCA2D[:,rindx],0)+np.mean(RPCA2D[:,rindx],0)\n",
    "        \n",
    "           \n",
    "    R2Score2D = np.zeros(1)\n",
    "    R2Score3D = np.zeros(1)\n",
    "    R2Score2D= r2_score(RPCA2D[:,rindx],out2d)\n",
    "    R2Score3D= r2_score(RPCA3D[:,rindx],out3d)   \n",
    "    \n",
    "    \n",
    "    return R2Score2D, R2Score3D, out2d, out3d,h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_LTC(data,dat3d):\n",
    "    labels2d = np.zeros(data.shape[0])\n",
    "    labels3d = np.zeros(dat3d.shape[0])\n",
    "    labels2d[data[:,3]>0.0001] = 1\n",
    "    labels3d[dat3d[:,3]>0.0001] = 1\n",
    "    return labels2d,labels3d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_valid, Y_train, Y_valid = train_test_split(Xt,data[:,42])\n",
    "def get_model_reac(dimi):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(24,input_dim=dimi,kernel_initializer='normal',kernel_regularizer=regularizers.l2(0.001)))\n",
    "    #model.add(GaussianNoise(0.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(rate=0.4))\n",
    "\n",
    "\n",
    "    model.add(Dense(24, kernel_initializer='normal',kernel_regularizer=regularizers.l2(0.001)))\n",
    "    #model.add(GaussianNoise(0.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(rate=0.4))\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(Dense(24, kernel_initializer='normal'))\n",
    "    #model.add(GaussianNoise(0.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    #model.add(Dense(10,kernel_initializer='normal'))\n",
    "    #model.add(GaussianNoise(0.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    \n",
    "\n",
    "    \n",
    "    #model.add(Dense(20,input_dim=dimi, kernel_initializer='normal',kernel_regularizer=regularizer.l2(0.0001)))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    \n",
    "   # model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    #model.add(Dense(60,input_dim=dimi, kernel_initializer='normal'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    \n",
    "    #model.add(Dropout(rate=0.4))\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    #model.add(Dropout(rate=0.3))\n",
    "    #sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(optimizer='nadam',loss='mean_squared_error')\n",
    "    return model\n",
    "    #model.add(relu(threshold=0.0))\n",
    "    #model.add(Dense(1,activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPCA2DN = do_normalization(RPCA2D,RPCA2D,'minmax')\n",
    "RPCA3DN = do_normalization(RPCA3D,RPCA2D,'minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model_reac(5)\n",
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=20,restore_best_weights=True)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xt[:,0:5],RPCA2DN[:,0],test_size=0.2,random_state=2)\n",
    "#mc = ModelCheckpoint('best_model.h5',monitor='val_loss',mode='min',save_best_only=True)\n",
    "h=model.fit(X_train,Y_train, validation_data=(X_test,Y_test),epochs=100,batch_size=128,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_conditional_average(bins,data,Xt):\n",
    "    out = np.zeros((bins,bins,bins))    \n",
    "    count = np.zeros((bins,bins,bins))    \n",
    "    for i in range(data.shape[0]):\n",
    "        ind = np.zeros()\n",
    "        ind1 = int((Xt[i,0]-min(Xt[:,0]))/(max(Xt[:,0])-min(Xt[i,0]))*bins)\n",
    "        ind2 = int((Xt[i,1]-min(Xt[:,1]))/(max(Xt[:,1])-min(Xt[i,1]))*bins)\n",
    "        ind3 = int((Xt[i,2]-min(Xt[:,2]))/(max(Xt[:,2])-min(Xt[i,2]))*bins)\n",
    "        out[ind1,ind2,ind3] = data[i]+out[ind1,ind2,ind3]\n",
    "        count[ind1,ind2,ind3] = count[ind1,ind2,ind3]+1\n",
    "    return out/(count+1)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_conditional_average(bins,data,Xt):\n",
    "    out = np.zeros((bins,bins))    \n",
    "    count = np.zeros((bins,bins))    \n",
    "    for i in range(data.shape[0]):        \n",
    "        ind1 = int((Xt[i,0]-min(Xt[:,0]))/(max(Xt[:,0])-min(Xt[:,0]))*bins)\n",
    "        ind2 = int((Xt[i,1]-min(Xt[:,1]))/(max(Xt[:,1])-min(Xt[:,1]))*bins)  \n",
    "        out[ind1,ind2] = data[i]+out[ind1,ind2]\n",
    "        count[ind1,ind2] = count[ind1,ind2]+1\n",
    "    return out/(count+1)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=0\n",
    "summ=0\n",
    "for i in range(len(b)):\n",
    "    #print(i)\n",
    "    indexx = b[i]//102-1\n",
    "    indexy = b[i]%102-1\n",
    "    err=err+(out[indexx,indexy]-RPCA3DN[i,0])**2\n",
    "    summ = summ+(RPCA3DN[i,0])**2\n",
    "    pred[i] = out[indexx,indexy]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_species(nClust,ep,nComp):\n",
    "    \n",
    "    mean_accuracy = np.zeros(6)\n",
    "    mean_accuracy2d = np.zeros(6)\n",
    "    out2d = np.empty([data.shape[0],53])\n",
    "    out3d = np.empty([dat3d.shape[0],53])    \n",
    "    \n",
    "    print(\"Making %d Clusters\",nClust)\n",
    "    labels2d,labels3d=do_clusters(nClust,Xt[:,0:nComp],Xt3d[:,0:nComp])\n",
    "    \n",
    "    for i in range(0,nClust):\n",
    "        print(\"Processing cluster %d\",i) \n",
    "        for spec in range(0,53):\n",
    "            \n",
    "             print(\"Processing Species \", spec)    \n",
    "             bsize = int(datanorm[labels2d==i,0].shape[0]/300)\n",
    "             if(bsize>800):\n",
    "                 bsize=800\n",
    "             if(bsize<100):\n",
    "                 bsize=100           \n",
    "                    \n",
    "#             model = get_model_species(nComp)\n",
    "             model.load_weights('model.h5')\n",
    "             model.fit(Xt[labels2d==i,0:nComp],datanorm[labels2d==i,spec],epochs=ep,batch_size=bsize)    \n",
    "             pred = model.predict(Xt[labels2d==i,0:nComp])\n",
    "             index2d = np.where(labels2d==i)\n",
    "             out2d[index2d,spec] = pred.T\n",
    "             pred = model.predict(Xt3d[labels3d==i,0:nComp])\n",
    "             if pred==[] or (not  pred.any()):\n",
    "                continue\n",
    "             index3d = np.where(labels3d==i)\n",
    "             out3d[index3d,[spec]] = pred.T\n",
    "        \n",
    "    out2d = out2d*(np.max(data[:,0:53],0)-np.min(data[:,0:53],0))+np.min(data[:,0:53],0)\n",
    "    out3d = out3d*(np.max(data[:,0:53],0)-np.min(data[:,0:53],0))+np.min(data[:,0:53],0)\n",
    "        \n",
    "    #atoms2D=get_atoms_conservation(data[:,0:53])\n",
    "    #atoms2D_pred=get_atoms_conservation(out2d[:,0:53])\n",
    "    #atoms3D=get_atoms_conservation(dat3d[:,0:53])\n",
    "    #atoms3D_pred=get_atoms_conservation(out3d[:,0:53])\n",
    "        \n",
    "    R2Score2D = np.zeros(53)\n",
    "    R2Score3D = np.zeros(53)\n",
    "    for i in range(0,53):\n",
    "            R2Score2D[i]= r2_score(data[:,i],out2d[:,i])\n",
    "            R2Score3D[i]= r2_score(dat3d[:,i],out3d[:,i])\n",
    "    mean_accuracy2d[0] = np.mean(R2Score2D)\n",
    "    mean_accuracy2d[1] = np.mean(abs(1-np.sum(out2d,1)))\n",
    "    \n",
    "    mean_accuracy[0] = np.mean(R2Score3D)\n",
    "    mean_accuracy[1] = np.mean(abs(1-np.sum(out3d,1)))\n",
    "    \n",
    "    #for j in range(0,4):\n",
    "    #    mean_accuracy2d[j+2] = np.mean(abs(1.0-atoms2D_pred[:,j]/atoms2D[:,j]))\n",
    "    #    mean_accuracy[j+2] = np.mean(abs(1.0-atoms3D_pred[:,j]/atoms3D[:,j]))       \n",
    "        \n",
    "    return mean_accuracy2d,mean_accuracy, R2Score2D, R2Score3D\n",
    "     \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
