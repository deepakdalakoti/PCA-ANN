{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notebook for analysis of a PCA-ANN based combustion model in diesel engine conditions  \n",
    "##### Ref: D.K. Dalakoti, A.â€¯Wehrfritz, B. Savard, M.S. Day, J.B. Bell, E.R. Hawkes, An a priori evaluation of a principal component and artificial neural network based combustion model in diesel engine conditions, Proc. Combust. Inst., https://doi.org/10.1016/j.proci.2020.06.263, (2020). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D \n",
    "import cantera as ct\n",
    "from cantera import ck2cti\n",
    "import os\n",
    "import time\n",
    "from helper_functions import read_data, read_reaction, do_normalization, do_inverse_norm, get_table_noholes, opt_est\n",
    "from neural_networks import get_model_species, get_model_reac, get_model_prop\n",
    "from helper_functions import get_cp, get_viscosity, get_conductivity, get_diffusion\n",
    "from neural_networks import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data for\n",
    "# 2D Data\n",
    "data = read_data('./RR_data/2D/data2d_lower2.bin',56)\n",
    "reac = read_reaction('./RR_data/2D/reac2d_lower2.bin')\n",
    "\n",
    "# Additional 2D for a different scalar dissipation rate case\n",
    "#data2 = read_data('./RR_data/data2d_base.bin',56)\n",
    "#reac2 = read_reaction('./RR_data/reac2d_base.bin')\n",
    "\n",
    "# Training can also be done using data from 0D reactors\n",
    "#data = np.fromfile('../PCA/data_0D.bin',dtype=np.single)\n",
    "#data = np.reshape(data,(56,int(data.size/56)))   \n",
    "#data = data.T\n",
    "#data = np.delete(data,0,1)\n",
    "\n",
    "#reac = np.fromfile('../PCA/reac_0D.bin',dtype=np.single)\n",
    "#reac = np.reshape(reac0D,(56,int(reac.size/56)))   \n",
    "#reac = reac.T\n",
    "#HRR = reac[:,0]\n",
    "#reac = np.delete(reac,0,1)\n",
    "#reac[:,53]=HRR\n",
    "#reac = np.delete(reac,54,1)\n",
    "\n",
    "# Training can also be done using 1D nonpremixed flamelets\n",
    "#data = get_data_2d('../PCA/data_25.h5')\n",
    "#reac = get_reac_2d('../PCA/data_25.h5')\n",
    "\n",
    "\n",
    "# 3D Data\n",
    "dat3d = read_data('./RR_data/3D/dat3d.bin',56)\n",
    "reac3d = read_reaction('./RR_data/3D/reac3d.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "nc=54\n",
    "datanorm = do_normalization(data[:,0:nc],data[:,0:nc],'range')\n",
    "dat3dnorm = do_normalization(dat3d[:,0:nc],data[:,0:nc],'range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA\n",
    "nc=54\n",
    "pca = PCA(n_components=5)\n",
    "Xt= pca.fit_transform(datanorm[:,0:nc])\n",
    "components = pca.components_\n",
    "# Subtract training mean because we are using training data to find PCA components\n",
    "Xt3d = np.matmul((dat3dnorm[:,0:nc]-np.mean(datanorm[:,0:nc],0)),components.T)\n",
    "np.sum(pca.explained_variance_ratio_)\n",
    "#XPCA = pca.inverse_transform(Xt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the PC reaction rates\n",
    "RPCA2D = np.matmul(reac[:,0:nc]/(np.max(data[:,0 :nc],0)-np.min(data[:,0:nc],0)),components.T)\n",
    "RPCA3D = np.matmul(reac3d[:,0:nc]/(np.max(data[:,0:nc],0)-np.min(data[:,0:nc],0)),components.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train neural network to learn species mass fractions\n",
    "model = get_model_species(5,53)\n",
    "trainSpec = training(model, Xt[:,0:5], data[:,0:53], 'std')\n",
    "trainSpec.do_training(2056,100)\n",
    "e1, e2 = trainSpec.get_errors(Xt3d, dat3d[:,0:53])\n",
    "sorted(list(zip(specs,e2)), key=lambda a: a[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train neural networks for prediction of PC reaction rates, one model for each RR\n",
    "trainRR = []\n",
    "errR2 = []\n",
    "errMSE = []\n",
    "pred = np.zeros((dat3d.shape[0],5))\n",
    "for i in range(0,5):\n",
    "    model = get_model_reac(5)\n",
    "    trainRR.append(training(model, Xt[:,0:5], RPCA2D[:,i:i+1], 'std'))\n",
    "    trainRR[i].do_training(1024,100)\n",
    "    #e1, e2 = trainRR[i].get_errors(Xt3d, RPCA3D[:,i:i+1])\n",
    "    #errR2.append(e1)\n",
    "    #errMSE.append(e2)\n",
    "    pred[:,i:i+1] = trainRR[i].get_predictions(Xt3d)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get cp for 2d and 3d dataset\n",
    "cp2d = get_cp(data)\n",
    "cp3d = get_cp(dat3d)\n",
    "\n",
    "# Train neural network to cp\n",
    "model = get_model_prop(5,1)\n",
    "traincp = training(model, Xt[:,0:5], cp2d[:,None], 'std')\n",
    "traincp.do_training(1024,100)\n",
    "e1, e2 = traincp.get_errors(Xt3d, cp3d[:,None])\n",
    "\n",
    "# Similarly get lambda, mu and mean molecular weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get diffusion coefficents of species\n",
    "D2D = get_diffusion(data[:,0:54])\n",
    "D3D = get_diffusion(dat3d[:,0:54])\n",
    "D2D = np.column_stack((D2D,cp2d))\n",
    "D3D = np.column_stack((D3D,cp3d))\n",
    "# Convert to diffusion coefficients of PCs\n",
    "DDPCA2D = np.matmul(D2D,components.T)\n",
    "DDPCA3D = np.matmul(D3D,components.T)\n",
    "\n",
    "\n",
    "model = get_model_prop(5,5)\n",
    "trainDiff = training(model, Xt[:,0:5], DDPCA2D, 'std')\n",
    "trainDiff.do_training(1024,100)\n",
    "e1, e2 = trainDiff.get_errors(Xt3d, DDPCA3D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal estimators for PC reaction rates\n",
    "opt_est_RR = np.zeros((RPCA3D.shape[0],5))\n",
    "for i in range(0,1):\n",
    "\n",
    "    opt_est_RR[:,i] = opt_est(Xt3d,RPCA3D[:,i],100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions of HRR based on conventional tabulation with mixture fraction and progress var\n",
    "HRR2d = np.copy(reac[:,53])\n",
    "HRR3d = np.copy(reac3d[:,53])\n",
    "idx_Y = [27,28,30,31] # CO + CO2 + H2 + H2O\n",
    "Yc2d = np.sum(data[:,idx_Y],axis=1)\n",
    "Yc3d = np.sum(dat3d[:,idx_Y],axis=1)\n",
    "xi2d = np.copy(data[:,54]) # Mixture fraction\n",
    "xi3d = np.copy(dat3d[:,54])\n",
    "Xtab2d = np.append(Yc2d[:,None],xi2d[:,None],axis=1)\n",
    "Xtab3d = np.append(Yc3d[:,None],xi3d[:,None],axis=1)\n",
    "\n",
    "pred = get_table_noholes(Xtab2d, HRR2d[:,None], Xtab3d, 200)\n",
    "\n",
    "# prediction based on first two PC based on conventional tabulation method\n",
    "predPCA = get_table_noholes(Xt[:,0:2], HRR2d[:,None], Xt3d[:,0:2], 200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting Fig. 4 in paper. To be used once neural networks are trained\n",
    "# Assuming pred contains neural network predictions\n",
    "# Sample code for OH mass fraction\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.scatter(dat3d[0:-1:100,42]/np.max(dat3d[0:-1:100,42]), pred[0:-1:100,42]/np.max(dat3d[0:-1:100,42]),marker='.',c='k',s=10)\n",
    "plt.locator_params(axis='y', nbins=3)\n",
    "plt.locator_params(axis='x', nbins=3)\n",
    "x = np.linspace(0.0,1.0,10)\n",
    "plt.plot(x,x,'r--')\n",
    "plt.xlabel('$DNS$')\n",
    "plt.ylabel('$ANN$')\n",
    "plt.title('$Y(OH)$')\n",
    "plt.xlim((0.0,1.0))\n",
    "plt.ylim((0.0,1.0))\n",
    "plt.grid(alpha=0.2)\n",
    "ax=plt.gca()\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(25)\n",
    "\n",
    "#plt.savefig('Final/OH2.png',dpi=300,bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import cond_mean\n",
    "# Error in the prediction of reaction rates, for Figure 3\n",
    "maxs = np.max(np.abs(RPCA3D),axis=0)\n",
    "eps = np.sum((RPCA3D-pred)**2,axis=1)\n",
    "nbins=100\n",
    "condAvg = cond_mean(Xt3d[:,0:2],eps,nbins)\n",
    "#condAvg = np.sqrt(condAvg)\n",
    "RO2 = cond_mean(Xt3d[:,0:2],dat3d[:,3],nbins)\n",
    "RO2[np.isnan(RO2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to plot Figure 3\n",
    "plt.figure()\n",
    "x = np.linspace(0,1,nbins)\n",
    "y = np.linspace(0,1,nbins)\n",
    "plt.contourf(x,y,np.sqrt(condAvg)/np.sum(maxs),cmap='jet',levels=100)\n",
    "plt.colorbar()\n",
    "plt.contour(x,y,RO2, levels=[0.0002],colors='red')\n",
    "\n",
    "#plt.clim(0,0.15)\n",
    "#plt.colorbar()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
